# ==========================================
# .github/workflows/deploy.yml - Complete CI/CD pipeline
# ==========================================
name: üöÄ TikSimPro CI/CD Pipeline

# Trigger conditions for the workflow
on:
  # Trigger on pushes to main and develop branches
  push:
    branches: [main, develop]
    paths-ignore:
      - "docs/**"
      - "*.md"
      - ".gitignore"

  # Trigger on pull requests to main
  pull_request:
    branches: [main]
    paths-ignore:
      - "docs/**"
      - "*.md"
      - ".gitignore"

  # Allow manual triggering from GitHub interface
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment"
        required: true
        default: "development"
        type: choice
        options:
          - development
          - staging
          - production
      skip_tests:
        description: "Skip test execution"
        required: false
        default: false
        type: boolean

# Global environment variables used across all jobs
env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Job 1: Code quality and testing
  quality-check:
    name: üîç Code Quality & Tests
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch full history for better analysis

      - name: üêç Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip" # Cache pip dependencies for faster builds

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov flake8 black isort mypy

      - name: üîç Code formatting check (Black)
        run: |
          black --check --diff src/ tests/

      - name: üìã Import sorting check (isort)
        run: |
          isort --check-only --diff src/ tests/

      - name: üîç Linting (flake8)
        run: |
          # Stop the build if there are Python syntax errors or undefined names
          flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
          # Treat all other issues as warnings
          flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: üîç Type checking (mypy)
        run: |
          mypy src/ --ignore-missing-imports --no-strict-optional
        continue-on-error: true # Don't fail the build on type errors yet

      - name: üß™ Run unit tests
        if: ${{ !inputs.skip_tests }}
        run: |
          pytest tests/ --cov=src/ --cov-report=xml --cov-report=html --junitxml=pytest.xml

      - name: üìä Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: |
            pytest.xml
            coverage.xml
          retention-days: 30

      - name: üìà Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: ${{ !inputs.skip_tests }}
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          token: ${{ secrets.CODECOV_TOKEN }}

  # Job 2: Build and publish Docker image
  build-image:
    name: üèóÔ∏è Build Docker Image
    needs: quality-check
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üîë Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: üè∑Ô∏è Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}

      - name: üèóÔ∏è Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

      - name: üîç Run security scan on image
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
          format: "sarif"
          output: "trivy-results.sarif"
        continue-on-error: true

      - name: üìã Upload security scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: "trivy-results.sarif"

  # Job 3: Deploy to development (develop branch)
  deploy-development:
    name: üöÄ Deploy to Development
    needs: build-image
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'development')
    environment:
      name: development
      url: https://tiksimpro-dev.your-domain.com

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: ‚öôÔ∏è Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "latest"

      - name: ‚öôÔ∏è Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: "latest"

      - name: üîê Configure kubeconfig
        run: |
          echo "${{ secrets.KUBE_CONFIG_DEVELOPMENT }}" | base64 -d > kubeconfig
          echo "KUBECONFIG=$(pwd)/kubeconfig" >> $GITHUB_ENV

      - name: üß™ Validate Kubernetes manifests
        run: |
          helm template tiksimpro-dev ./helm/tiksimpro \
            --namespace tiksimpro-development \
            --values ./helm/tiksimpro/values.yaml \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ github.sha }} \
            --dry-run=client > /dev/null

      - name: üöÄ Deploy to development
        run: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update

          helm upgrade --install tiksimpro-dev ./helm/tiksimpro \
            --namespace tiksimpro-development \
            --create-namespace \
            --values ./helm/tiksimpro/values.yaml \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ github.sha }} \
            --set global.environment=development \
            --timeout 10m \
            --wait \
            --atomic

      - name: üîç Verify deployment
        run: |
          kubectl get pods -n tiksimpro-development
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=tiksimpro -n tiksimpro-development --timeout=300s

      - name: üß™ Run smoke tests
        run: |
          # Wait for services to be fully ready
          sleep 30

          # Test that the web interface is accessible
          kubectl port-forward svc/tiksimpro-web 8080:80 -n tiksimpro-development &
          sleep 10

          # Basic health check
          curl -f http://localhost:8080/health || echo "Health check endpoint not yet available"

          # Stop port forwarding
          pkill -f "kubectl port-forward"

  # Job 4: Deploy to staging (main branch, before production)
  deploy-staging:
    name: üöÄ Deploy to Staging
    needs: build-image
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'staging')
    environment:
      name: staging
      url: https://tiksimpro-staging.your-domain.com

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: ‚öôÔ∏è Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "latest"

      - name: ‚öôÔ∏è Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: "latest"

      - name: üîê Configure kubeconfig
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
          echo "KUBECONFIG=$(pwd)/kubeconfig" >> $GITHUB_ENV

      - name: üöÄ Deploy to staging
        run: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update

          helm upgrade --install tiksimpro-staging ./helm/tiksimpro \
            --namespace tiksimpro-staging \
            --create-namespace \
            --values ./helm/tiksimpro/values-staging.yaml \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ github.sha }} \
            --set global.environment=staging \
            --timeout 15m \
            --wait \
            --atomic

      - name: üîç Verify deployment
        run: |
          kubectl get pods -n tiksimpro-staging
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=tiksimpro -n tiksimpro-staging --timeout=300s

      - name: üß™ Run integration tests
        run: |
          # Extended testing for staging environment
          echo "Running integration tests..."

          # Test database connectivity
          kubectl exec -n tiksimpro-staging deployment/tiksimpro-postgresql -- pg_isready -U tiksimpro

          # Test Redis connectivity
          kubectl exec -n tiksimpro-staging deployment/tiksimpro-redis-master -- redis-cli ping

  # Job 5: Deploy to production (manual approval required)
  deploy-production:
    name: üöÄ Deploy to Production
    needs: [build-image, deploy-staging]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && inputs.environment == 'production')
    environment:
      name: production
      url: https://tiksimpro.your-domain.com

    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: ‚öôÔ∏è Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: "latest"

      - name: ‚öôÔ∏è Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: "latest"

      - name: üîê Configure kubeconfig
        run: |
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > kubeconfig
          echo "KUBECONFIG=$(pwd)/kubeconfig" >> $GITHUB_ENV

      - name: üíæ Backup current deployment
        run: |
          # Create backup of current Helm values
          helm get values tiksimpro-prod -n tiksimpro-production > production-backup-$(date +%Y%m%d-%H%M%S).yaml || echo "No existing deployment to backup"

      - name: üöÄ Deploy to production
        run: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo update

          helm upgrade --install tiksimpro-prod ./helm/tiksimpro \
            --namespace tiksimpro-production \
            --create-namespace \
            --values ./helm/tiksimpro/values-production.yaml \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ github.sha }} \
            --set global.environment=production \
            --timeout 20m \
            --wait \
            --atomic

      - name: üîç Verify production deployment
        run: |
          kubectl get pods -n tiksimpro-production
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=tiksimpro -n tiksimpro-production --timeout=600s

          # Verify all expected pods are running
          expected_pods=$(kubectl get statefulset -n tiksimpro-production -l app.kubernetes.io/name=tiksimpro -o jsonpath='{.items[*].spec.replicas}' | tr ' ' '+' | bc)
          actual_pods=$(kubectl get pods -n tiksimpro-production -l app.kubernetes.io/name=tiksimpro --field-selector=status.phase=Running --no-headers | wc -l)

          if [ "$actual_pods" -eq "$expected_pods" ]; then
            echo "‚úÖ All $actual_pods pods are running successfully"
          else
            echo "‚ùå Expected $expected_pods pods, but only $actual_pods are running"
            exit 1
          fi

      - name: üß™ Run production health checks
        run: |
          # Comprehensive health checks for production
          echo "Running production health checks..."

          # Check all pods are healthy
          kubectl get pods -n tiksimpro-production -l app.kubernetes.io/name=tiksimpro

          # Test database connectivity
          kubectl exec -n tiksimpro-production deployment/tiksimpro-postgresql -- pg_isready -U tiksimpro

          # Test Redis connectivity
          kubectl exec -n tiksimpro-production deployment/tiksimpro-redis-master -- redis-cli ping

          # Check service endpoints
          kubectl get endpoints -n tiksimpro-production

      - name: üìä Post-deployment monitoring setup
        run: |
          echo "Setting up post-deployment monitoring..."

          # Ensure monitoring is working
          kubectl get pods -n tiksimpro-production -l app.kubernetes.io/name=prometheus
          kubectl get pods -n tiksimpro-production -l app.kubernetes.io/name=grafana

      - name: üì¢ Notify deployment success
        if: success()
        run: |
          echo "üéâ Production deployment successful!"
          echo "Version: ${{ github.sha }}"
          echo "Environment: production"
          echo "Timestamp: $(date)"
          # Add notification to Slack/Discord/Teams here if configured

  # Job 6: Cleanup old images and failed deployments
  cleanup:
    name: üßπ Cleanup
    needs: [deploy-development, deploy-staging, deploy-production]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: üóëÔ∏è Delete old container images
        uses: actions/delete-package-versions@v4
        with:
          package-name: ${{ env.IMAGE_NAME }}
          package-type: "container"
          min-versions-to-keep: 10
          delete-only-untagged-versions: true
